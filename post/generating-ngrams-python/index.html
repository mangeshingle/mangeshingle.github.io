
<!DOCTYPE html>
<html lang="en-us">

<!-- Mirrored from www.albertauyeung.com/post/generating-ngrams-python/ by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 02 Nov 2018 14:48:01 GMT -->
<head>

  
  <meta charset="UTF-8">
  <title>
    Generating N-grams from Sentences Python | Albert Au Yeung
  </title>


  
  <meta name="viewport" content="width=device-width,user-scalable=no,maximum-scale=1,initial-scale=1">

  
  <link rel="canonical" href="index.html"/>

  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans">
  <link rel="stylesheet" href="../../css/sanitize.css">
  <link rel="stylesheet" href="../../css/responsive.css">
  <link rel="stylesheet" href="../../css/highlight.css">
  <link rel="stylesheet" href="../../css/theme.css">
  <link rel="stylesheet" href="../../css/custom.css">
  
  
  <link href="../../index.xml" rel="alternate" type="application/rss+xml" title="Albert Au Yeung" />
  <link href="../../index.xml" rel="feed" type="application/rss+xml" title="Albert Au Yeung" />

  
  


</head>



<body>
<div class="container">

  
  <header role="banner">
    <div class="row gutters">
      <div id="site-title" class="col span_6">
        <h1><a href="../../index.html">Albert Au Yeung</a></h1>
        <h2>Notes on machine learning and A.I.</h2>
      </div>
      <div id="social" class="col span_6">
        <ul>
          <li><a href="../../about/index.html">About</a></li>
          <li><a href="../index.html">Archive</a></li>
          <li><a href="https://github.com/albertauyeung" target="_blank">Github</a></li>
          <li><a href="https://www.linkedin.com/in/albert-au-yeung/" target="_blank">LinkedIn</a></li>
        </ul>
      </div>
    </div>
  </header>


  
  <main id="single" role="main">
    <div class="article-header">
      <h1>Generating N-grams from Sentences Python</h1>
      <div class="meta">
        
        Jun 3, 2018 &nbsp;
        
        
      </div>
    </div>
    <article>
      

<p><a href="https://en.wikipedia.org/wiki/N-gram">N-grams</a> are contiguous sequences of n-items in a sentence. N can be 1, 2 or any other positive integers, although usually we do not consider very large N because those n-grams rarely appears in many different places.</p>

<p>When performing machine learning tasks related to natural language processing, we usually need to generate n-grams from input sentences. For example, in text classification tasks, in addition to using each individual token found in the corpus, we may want to add bi-grams or tri-grams as features to represent our documents. This post describes several different ways to generate n-grams quickly from input sentences in Python.</p>

<h2 id="the-pure-python-way">The Pure Python Way</h2>

<p>In general, an input sentence is just a string of characters in Python. We can use build in functions in Python to generate n-grams quickly. Let&rsquo;s take the following sentence as a sample input:</p>

<pre><code class="language-python">s = &quot;Natural-language processing (NLP) is an area of computer science &quot; \
    &quot;and artificial intelligence concerned with the interactions &quot; \
    &quot;between computers and human (natural) languages.&quot;
</code></pre>

<p>If we want to generate a list of bi-grams from the above sentence, the expected output would be something like below (depending on how do we want to treat the punctuations, the desired output can be different):</p>

<pre><code class="language-python">[
    &quot;natural language&quot;,
    &quot;language processing&quot;,
    &quot;processing nlp&quot;,
    &quot;nlp is&quot;,
    &quot;is an&quot;,
    &quot;an area&quot;,
    ...
]
</code></pre>

<p>The following function can be used to achieve this:</p>

<pre><code class="language-python">import re

def generate_ngrams(s, n):
    # Convert to lowercases
    s = s.lower()
    
    # Replace all none alphanumeric characters with spaces
    s = re.sub(r'[^a-zA-Z0-9\s]', ' ', s)
    
    # Break sentence in the token, remove empty tokens
    tokens = [token for token in s.split(&quot; &quot;) if token != &quot;&quot;]
    
    # Use the zip function to help us generate n-grams
    # Concatentate the tokens into ngrams and return
    ngrams = zip(*[token[:i] for i in range(n)])
    return [&quot; &quot;.join(ngram) for ngram in ngrams]
</code></pre>

<p>Applying the above function to the sentence, with <code>n=5</code>, gives the following output:</p>

<pre><code class="language-python">&gt;&gt;&gt; generate_ngrams(s, n=5)
['natural language processing nlp is',
 'language processing nlp is an',
 'processing nlp is an area',
 'nlp is an area of',
 'is an area of computer',
 'an area of computer science',
 'area of computer science and',
 'of computer science and artificial',
 'computer science and artificial intelligence',
 'science and artificial intelligence concerned',
 'and artificial intelligence concerned with',
 'artificial intelligence concerned with the',
 'intelligence concerned with the interactions',
 'concerned with the interactions between',
 'with the interactions between computers',
 'the interactions between computers and',
 'interactions between computers and human',
 'between computers and human natural',
 'computers and human natural languages']
</code></pre>

<p>The above function makes use of the <code>zip</code> function, which creates a generator that aggregates elements from multiple lists (or iterables in genera). The blocks of codes and comments below offer some more explanation of the usage:</p>

<pre><code class="language-python"># Sample sentence
s = &quot;one two three four five&quot;

tokens = s.split(&quot; &quot;)
# tokens = [&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;, &quot;five&quot;]

sequences = [tokens[i:] for i in range(3)]
# The above will generate sequences of tokens starting from different
# elements of the list of tokens.
# The parameter in the range() function controls how many sequences
# to generate.
#
# sequences = [
#   ['one', 'two', 'three', 'four', 'five'],
#   ['two', 'three', 'four', 'five'],
#   ['three', 'four', 'five']]

bigrams = zip(*sequences)
# The zip function takes the sequences as a list of inputs (using the * operator,
# this is equivalent to zip(sequences[0], sequences[1], sequences[2]).
# Each tuple it returns will contain one element from each of the sequences.
# 
# To inspect the content of bigrams, try:
# print(list(bigrams))
# which will give the following:
#
# [('one', 'two', 'three'), ('two', 'three', 'four'), ('three', 'four', 'five')]
#
# Note: even though the first sequence has 5 elements, zip will stop after returning
# 3 tuples, because the last sequence only has 3 elements. In other words, the zip
# function automatically handles the ending of the n-gram generation.
</code></pre>

<h2 id="using-nltk">Using NLTK</h2>

<p>Instead of using pure Python functions, we can also get help from some natural language processing libraries such as the <a href="https://www.nltk.org/">Natural Language Toolkit (NLTK)</a>. In particular, nltk has the <code>ngrams</code> function that returns a generator of n-grams given a tokenized sentence. (See the documentaion of the function <a href="http://www.nltk.org/api/nltk.html#nltk.util.ngrams">here</a>)</p>

<pre><code class="language-python">import re
from nltk.util import ngrams

s = s.lower()
s = re.sub(r'[^a-zA-Z0-9\s]', ' ', s)
tokens = [token for token in s.split(&quot; &quot;) if token != &quot;&quot;]
output = list(ngrams(tokens, 5))
</code></pre>

<p>The above block of code will generate the same output as the function <code>generate_ngrams()</code> as shown above.</p>

      
      
      
    </article>
    
    
 <aside><div id="disqus_thread"></div></aside>

<script type="text/javascript">
     
    var disqus_shortname = 'albertauyeung';

     
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



    
  </main>
  
  <nav class="pagination-single">
    <center>
      <a href="#">Back to Top</a>
    </center>
    
  </nav>


  
  <footer role="contentinfo">
    <div style="text-align:center; font-size: 0.8em">
      Copyright Â© 2017 Albert Au Yeung. All Rights Reserved.
    </div>
  </footer>


</div>

<script src="../../js/jquery-3.2.1.min.js"></script>
<script src="../../js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src="../../../cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script>
$(document).ready(function() {
  var links = document.querySelectorAll('article a');
    for (var i = 0, length = links.length; i < length; i++) {
      if (links[i].hostname != window.location.hostname) {
        links[i].target = '_blank';
      }
  }
});
</script>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','../../../www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-30554548-1', 'auto');
	ga('send', 'pageview');
</script>

</body>

<!-- Mirrored from www.albertauyeung.com/post/generating-ngrams-python/ by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 02 Nov 2018 14:48:01 GMT -->
</html>

